# DocuWise â€“ Adobe India Hackathon 2025

DocuWise is a full-stack application that transforms PDF libraries into interactive, AI-powered knowledge companions. It enables users to upload, browse, analyze, and interact with documents, while providing generative AI insights, semantic snippet recommendations, and even podcast-style narrations.

## âœ¨ Features

### ğŸ“‚ Document Management
- Upload single current PDFs and multiple historical PDFs.
- Highlight the latest "current" document (color-coded for easy identification).
- Delete PDFs directly from the sidebar.

### ğŸ“– High-Fidelity Viewer
- Seamless PDF rendering using Adobe PDF Embed API.
- Sidebar navigation and jump-to-snippet functionality.

### ğŸ¤– AI-Powered Insights
- Extract cross-document snippets dynamically.
- Insights categorized with color codes:
  - ğŸŸ¢ Did you know? facts
  - ğŸ”µ Examples
  - ğŸ”´ Contradictions / Counterpoints
  - ğŸŸ¡ Key Takeaways

### ğŸ™ Podcast Generation
- Generate natural-sounding audio summaries of insights using Google TTS.
- Multi-speaker mode supported.

### ğŸ’¬ AI Chat
- Ask follow-up, context-aware questions about any PDF section.

### ğŸŒ Hybrid Online/Offline Mode
- **Online Mode** â†’ Uses Gemini 2.5 LLM + Google TTS for powerful insights.
- **Offline Mode** â†’ Local inference for faster but lightweight results.

---

## ğŸ“‚ Project Structure

```
Connecting-the-Dots/
â”‚
â”œâ”€â”€ backend/                   # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPI entry
â”‚   â”‚   â”œâ”€â”€ routes/             # API endpoints (/ingest, /recommend, /insights, /podcast)
â”‚   â”‚   â”œâ”€â”€ services/           # LLM + TTS services
â”‚   â”‚   â””â”€â”€ engines/
â”‚   â”‚       â”œâ”€â”€ round1a/        # Challenge 1A: PDF structure extraction
â”‚   â”‚       â””â”€â”€ round1b/        # Challenge 1B: Persona-driven insights
â”‚   â”œâ”€â”€ storage/                # Uploaded documents, outputs
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ frontend/                  # React + Vite + TS frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # PDF viewer, Sidebar, Snippet cards
â”‚   â”‚   â”œâ”€â”€ api/                # Axios API clients
â”‚   â”‚   â”œâ”€â”€ store/              # Zustand state management
â”‚   â”‚   â””â”€â”€ App.tsx
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md
```

---

## ğŸ”‘ Environment Variables

**Frontend (`frontend/.env`):**
```
VITE_BACKEND_URL=http://localhost:8080
ADOBE_EMBED_API_KEY=af20ec0567274e08b77b9473d6f0485f 
```

**Backend / Docker:**  
These are passed at runtime (not hardcoded in code):

- `ADOBE_EMBED_API_KEY` â†’ (provided by candidate)
- `LLM_PROVIDER=gemini`
- `GOOGLE_APPLICATION_CREDENTIALS=/credentials/adbe-gcp.json`
- `GEMINI_MODEL=gemini-2.5-flash`
- `TTS_PROVIDER=gcp`
- `AZURE_TTS_KEY`, `AZURE_TTS_ENDPOINT` (for evaluation, set by Adobe)

---

## ğŸ–¥ Local Development

### 1. Backend
```sh
cd backend
python -m venv venv
venv\Scripts\activate   # Windows
source venv/bin/activate   # Linux/Mac

pip install -r requirements.txt

# Run with Gemini + Google TTS (online mode)
$env:MODE="online"
$env:GEMINI_API_KEY="your_gemini_api_key"
$env:LLM_PROVIDER="gemini"
$env:GEMINI_MODEL="gemini-2.5-flash"
$env:TTS_PROVIDER="gcp"

uvicorn app.main:app --host 0.0.0.0 --port 8080 --reload
```

### 2. Frontend
```sh
cd frontend
npm install
npm run dev
```

- Backend â†’ http://localhost:8080
- Frontend â†’ http://localhost:5173

---

## ğŸ³ Docker (Evaluation Mode)

**Build**
```sh
docker build --platform linux/amd64 -t docuwise .
```

**Run**
```sh
docker run \
  -v /path/to/credentials:/credentials \
  -e ADOBE_EMBED_API_KEY=<ADOBE_EMBED_API_KEY> \
  -e LLM_PROVIDER=gemini \
  -e GOOGLE_APPLICATION_CREDENTIALS=/credentials/adbe-gcp.json \
  -e GEMINI_MODEL=gemini-2.5-flash \
  -e TTS_PROVIDER=azure \
  -e AZURE_TTS_KEY=<TTS_KEY> \
  -e AZURE_TTS_ENDPOINT=<TTS_ENDPOINT> \
  -p 8080:8080 docuwise
```

ğŸ‘‰ Open: http://localhost:8080  
This will serve both frontend + backend from the same container.

---

## ğŸ“¦ Dependencies

**Main backend dependencies (`backend/requirements.txt`):**
- langchain==0.3.27
- langchain-openai==0.3.29
- langchain-google-genai==2.0.10
- langchain-community==0.3.27
- google-generativeai==0.8.5
- google-cloud-texttospeech==2.27.0
- pydub>=0.25.0
- requests>=2.25.0
- fastapi
- uvicorn

**Frontend:**
- React + Vite + TypeScript
- Zustand (state)
- TailwindCSS (styling)
- Axios (API)

---

## ğŸ§ª Notes for Evaluators

- âœ… Single Docker image serves frontend + backend on port 8080.
- âœ… No keys are hardcoded â€” all are injected via environment variables.
- âœ… Supports Gemini 2.5 for LLM and Google/Azure TTS for podcasting.
- âœ… Works fully offline with fallback
